{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'pandas.core.series.Series\\'>\"})'}), <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_99_input to have shape (24,) but got array with shape (7,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-2e16990f1d39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m           verbose=True)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    572\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    575\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_99_input to have shape (24,) but got array with shape (7,)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the data from excel home \n",
    "data_mda = pd.read_excel('C:/Users/ERIC/Desktop/Jupyter/PML_AÑO_HORA_DIA.xlsx',2,)\n",
    "data_mtr = pd.read_excel('C:/Users/ERIC/Desktop/Jupyter/PML_AÑO_HORA_DIA.xlsx',3)\n",
    "\n",
    "# read the data from excel ORCA\n",
    "#data = pd.read_excel('C:/Users/Operaciones F/Forecast_Demand/Forecaste_PML_Daily_b.xlsx')\n",
    "'''\n",
    "\n",
    "# create a new plot with a title and axis labels\n",
    "p = figure(title=\"PML's DAILY BEHAVIOUR 2018\", x_axis_label='TIEMPO [MESES]', y_axis_label='[$ / MWh ]')\n",
    "\n",
    "# add the data\n",
    "\n",
    "p.line(data['MES'], data['lun_18'], legend_label = \"Lunes 2018\", color = 'blue')\n",
    "\n",
    "# show the results\n",
    "show(p)\n",
    "\n",
    "# output to static HTML file\n",
    "output_file(\"PML2018.html\")\n",
    "'''\n",
    "# Adding data to the training variables \n",
    "'''\n",
    "x_train = [\n",
    "           [data_mda[1]],[data_mda[2]],[data_mda[3]],[data_mda[4]],[data_mda[5]],[data_mda[6]],[data_mda[7]],\n",
    "           [data_mda[8]],[data_mda[9]],[data_mda[10]],[data_mda[11]],[data_mda[12]],[data_mda[13]],\n",
    "           [data_mda[14]],[data_mda[15]],[data_mda[16]],[data_mda[17]],[data_mda[18]],[data_mda[19]],\n",
    "           [data_mda[20]],[data_mda[21]],[data_mda[22]],[data_mda[23]],[data_mda[24]]\n",
    "            ]\n",
    "'''          \n",
    "    \n",
    "from tensorflow.keras.layers import Dense, Add\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Create the layers\n",
    "model.add(Dense(50, input_shape = (24,)))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(24, activation = 'sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.01), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "\n",
    "# Summarize the model\n",
    "#model.summary()\n",
    "\n",
    "# Now fit the model\n",
    "\n",
    "model.fit( [\n",
    "           [data_mda[1]],[data_mda[2]],[data_mda[3]],[data_mda[4]],[data_mda[5]],[data_mda[6]],[data_mda[7]],\n",
    "           [data_mda[8]],[data_mda[9]],[data_mda[10]],[data_mda[11]],[data_mda[12]],[data_mda[13]],\n",
    "           [data_mda[14]],[data_mda[15]],[data_mda[16]],[data_mda[17]],[data_mda[18]],[data_mda[19]],\n",
    "           [data_mda[20]],[data_mda[21]],[data_mda[22]],[data_mda[23]],[data_mda[24]]\n",
    "            ],\n",
    "          [\n",
    "           [data_mtr[1]],[data_mtr[2]],[data_mtr[3]],[data_mtr[4]],[data_mtr[5]],[data_mtr[6]],[data_mtr[7]],\n",
    "           [data_mtr[8]],[data_mtr[9]],[data_mtr[10]],[data_mtr[11]],[data_mtr[12]],[data_mtr[13]],\n",
    "           [data_mtr[14]],[data_mtr[15]],[data_mtr[16]],[data_mtr[17]],[data_mtr[18]],[data_mtr[19]],\n",
    "           [data_mtr[20]],[data_mtr[21]],[data_mtr[22]],[data_mtr[23]],[data_mtr[24]]\n",
    "            ],\n",
    "          epochs=10,\n",
    "          batch_size=3,\n",
    "          validation_split=0.2,\n",
    "          verbose=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
