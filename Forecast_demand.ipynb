{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 9 samples\n",
      "Epoch 1/53\n",
      "32/32 [==============================] - 1s 20ms/sample - loss: 241722.6372 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6362 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6392 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6406 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/53\n",
      "32/32 [==============================] - 0s 997us/sample - loss: 241722.6318 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6372 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6396 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6343 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6440 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/53\n",
      "32/32 [==============================] - 0s 997us/sample - loss: 241722.6421 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6411 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6313 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6387 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6348 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6333 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6343 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6416 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6343 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/53\n",
      "32/32 [==============================] - 0s 997us/sample - loss: 241722.6465 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6406 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6465 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/53\n",
      "32/32 [==============================] - 0s 935us/sample - loss: 241722.6392 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6387 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/53\n",
      "32/32 [==============================] - 0s 997us/sample - loss: 241722.6445 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6426 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/53\n",
      "32/32 [==============================] - 0s 966us/sample - loss: 241722.6411 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6377 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/53\n",
      "32/32 [==============================] - 0s 966us/sample - loss: 241722.6431 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6396 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6343 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6431 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/53\n",
      "32/32 [==============================] - 0s 998us/sample - loss: 241722.6421 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6387 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/53\n",
      "32/32 [==============================] - 0s 997us/sample - loss: 241722.6392 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6392 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/53\n",
      "32/32 [==============================] - 0s 965us/sample - loss: 241722.6396 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6323 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6348 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6411 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/53\n",
      "32/32 [==============================] - 0s 1ms/sample - loss: 241722.6309 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6357 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6377 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6392 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6401 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6445 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6416 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6406 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6372 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6440 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6411 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6470 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6396 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/53\n",
      "32/32 [==============================] - 0s 2ms/sample - loss: 241722.6406 - accuracy: 0.0312 - val_loss: 218668.6389 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x163863d1e08>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# read the data from excel home \n",
    "#data_mda = pd.read_excel('C:/Users/ERIC/Desktop/Jupyter/PML 09LBR LUNES HORORIO.xlsx',2)\n",
    "#data_mda_y = pd.read_excel('C:/Users/ERIC/Desktop/Jupyter/PML_AÑO_HORA_DIA.xlsx',3)\n",
    "\n",
    "# read the data from excel ORCA\n",
    "data_mda = pd.read_excel('C:/Users/Operaciones F/Forecast_Demand/PML 09LBR LUNES HORORIO.xlsx',2)\n",
    "#data_mda_y = pd.read_excel('C:/Users/Operaciones F/Forecast_Demand/PML 09LBR LUNES HORORIO.xlsx',3)\n",
    "\n",
    "'''\n",
    "# create a new plot with a title and axis labels\n",
    "p = figure(title=\"PML's DAILY BEHAVIOUR 2018\", x_axis_label='TIEMPO [DÍAS]', y_axis_label='[$ / MWh ]')\n",
    "\n",
    "# add the data\n",
    "\n",
    "p.line(data_mda['Num'], data_mda[1], legend_label = \"HORA 1\", color = 'blue')\n",
    "\n",
    "# show the results\n",
    "show(p)\n",
    "\n",
    "# output to static HTML file\n",
    "output_file(\"PML2018.html\")\n",
    "'''\n",
    "\n",
    "\n",
    "# Splitting the training and test set into a 80/20 proportion\n",
    "data_mda = data_mda.reindex(np.random.permutation(data_mda.index))\n",
    "mask  = np.random.rand(len(data_mda)) < 0.8\n",
    "data_mda_train = pd.DataFrame(data_mda[mask])\n",
    "data_mda_test = pd.DataFrame(data_mda[~mask])\n",
    "\n",
    "\n",
    "# Declaring the dataset for x tain\n",
    "x_train = data_mda_train.iloc[:, 1:2].values\n",
    "# Declaring the dataset for y tain\n",
    "y_train = data_mda_train.iloc[:, 2:26].values\n",
    "\n",
    "'''\n",
    "                                                    # MODEL WITH KERAS\n",
    "from tensorflow.keras.layers import Dense, Add\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Creating input layers\n",
    "model.add(Dense(100, input_shape = (1,)))\n",
    "\n",
    "# Creating hidden layers\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(500, activation = 'sigmoid'))\n",
    "\n",
    "# Creating the ouput\n",
    "model.add(Dense(24))\n",
    "'''\n",
    "                                                # MODEL WITH TENSORFLOW\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense\n",
    "\n",
    "input_tensor = Input(shape = (1,))\n",
    "\n",
    "hidden_layer_1 = Dense(5, activation = 'linear')(input_tensor)\n",
    "hidden_layer_2 = Dense(5, activation = 'sigmoid')(hidden_layer_1)\n",
    "hidden_layer_3 = Dense(5, activation = 'sigmoid')(hidden_layer_2)\n",
    "\n",
    "ouput_tensor = Dense(24)(hidden_layer_3)\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Summarize the model\n",
    "#model.summary()\n",
    "\n",
    "# Now fit the model\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=53,\n",
    "          batch_size=5,\n",
    "          validation_split=0.2,\n",
    "          verbose=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
